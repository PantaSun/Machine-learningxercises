{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树实践\n",
    "\n",
    "### 简介\n",
    ">机器学习中，决策树是一个预测模型；他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表某个可能的属性值，而每个叶节点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。 数据挖掘中决策树是一种经常要用到的技术，可以用于分析数据，同样也可以用来作预测。\n",
    "从数据产生决策树的机器学习技术叫做决策树学习,通俗说就是决策树。 ----摘自[维基百科](https://zh.wikipedia.org/wiki/%E5%86%B3%E7%AD%96%E6%A0%91)\n",
    "\n",
    "### 优缺点及适用数据类型\n",
    "> \n",
    "  - 优点：计算复杂度不高，输出结果容易理解，对中间值的缺失不敏感，可以处理不相关特征数据。\n",
    "  - 缺点：可能会产生过度匹配\n",
    "  - 适用数据类型：数值型和标称型\n",
    "\n",
    "### 决策树构造\n",
    "  \n",
    "  决策树的主要思想就是对数据集按照一定的规则进行划分，其大致的算法流程伪码如下：\n",
    "  \n",
    "```\n",
    "  def createBranch():\n",
    "      if 数据集中每一个样本都属于同一分类：\n",
    "          return 类别标签\n",
    "      else:\n",
    "          找到最先用来划分数据集的特征\n",
    "          划分数据集\n",
    "          创建分支节点\n",
    "              for 每个数据子集：\n",
    "                  调用createBranch()\n",
    "          return 分支节点\n",
    "       \n",
    "``` \n",
    "  因此在构造决策树时最主要的问题就是找到当前数据集中用来最先进行划分数据集的特征，也就是说在将数据集分类时，我们应该先根据哪个特征来进行划分，这里可以将这个特征成为最优特征。关于最优特征目前有很多算法。\n",
    ">常用决策树算法有ID3，C4.5和CART。它们都是采用贪心（即非回溯的）方法，自顶向下递归的分治方法构造。这几个算法选择属性划分的方法各不相同，ID3使用的是信息增益，C4.5使用的是信息增益率，而CART使用的是Gini基尼指数。\n",
    "\n",
    "### 常用算法及Python实现\n",
    "*下面只对ID3算法进行代码实现。*\n",
    "#### ID3算法\n",
    ">ID3算法（Iterative Dichotomiser 3 迭代二叉树3代）是一个由Ross Quinlan发明的用于决策树的算法。\n",
    "这个算法是建立在奥卡姆剃刀的基础上：越是小型的决策树越优于大的决策树（简单理论）。尽管如此，该算法也不是总是生成最小的树形结构。而是一个启发式算法。奥卡姆剃刀阐述了一个信息熵的概念：$$I_E(i)=-\\sum_{j=1}^{m}f(i,j)log_2f(i,j))$$\n",
    "\n",
    "\n",
    ">熵被用来衡量一个随机变量出现的期望值。熵越大，一个变量的不确定性就越大（也就是可取的值很多），把它搞清楚所需要的信息量也就越大，熵是整个系统的平均消息量。 信息熵是信息论中用于度量信息量的一个概念。一个系统越是有序，信息熵就越低；反之，一个系统越是混乱，信息熵就越高。所以，信息熵也可以说是系统有序化程度的一个度量。\n",
    "\n",
    "##### 熵（Entropy）的计算公式\n",
    "\n",
    ">熵定义为信息的期望值。先看看信息的定义：\n",
    "\n",
    ">$$l(x_i)=−log_2p(x_i)$$\n",
    "\n",
    ">其中，$p(x_i)$是选择该分类的概率。对D中的元组所有分类所有可能值的信息期望，即熵，计算公式如下：\n",
    "\n",
    ">$$Entropy=H(D)=E(I(D))=−\\sum_{i}^{n}p_ilog_2(p_i)$$ $p_i$是D中任意元组属于类$C_i$非零概率。\n",
    "熵越大，说明系统越混乱，携带的信息就越少。熵越小，说明系统越有序，携带的信息就越多。信息的作用就是在于消除不确定性。\n",
    "\n",
    ">ID3划分特征使用的就是信息增益IG。一个属性的信息增益越大，表明属性对样本的熵减少的能力就更强，该属性使得数据所属类别的不确定性变为确定性的能力越强。信息增益在统计学中称为互信息，互信息是条件概率与后验概率的比值，化简之后就可以得到信息增益。所以说互信息其实就是信息增益。计算方法【互信息=熵-条件熵】。熵描述的是不确定性。熵越大，不确定性就越大，条件熵H（B|A）描述的是在A给定的条件下B的不确定性，如果条件熵越小，表示不确定性就越小，那么B就越容易确定结果。所以使用熵减去条件熵，就得到了信息增益，他描述的不确定性的降低程度，可以用来度量两个变量的相关性。比如，在给定一个变量的条件下，另一个变量它的不确定性能够降低多少，如果不确定性降低得越多，那么它的确定性就越大，就越容易区分，两者就越相关。注：期望信息越小，分区的纯度越高。\n",
    "\n",
    "##### 信息增益计算\n",
    "\n",
    ">首先计算特征A对数据集D的经验条件熵H(D|A),在数学上就是条件概率分布（Condition Probability）.\n",
    "\n",
    ">$$H(D|A)=\\sum_{j}\\cfrac{|D_j|}{|D|}×H(D_j)$$，项$\\cfrac{|D_j|}{|D|}$充当第j个分区的权重\n",
    "引入条件熵，在信息论中主要是为了消除结果的不确定性。然后计算信息增益\n",
    "\n",
    ">$$Gain(A)=H(D)−H(D|A)$$\n",
    "其中，Gain(A)即为所求的信息增益。\n",
    "\n",
    "##### 代码实现\n",
    "###### 创建产生测试数据的方法\n",
    "测试数据如下表“海洋生物数据”所示，为了方便处理将两个特征的“是”和“否”分别用“1”和“0”代替，分类标签的“是”和“否”分别用“yes”和“no”代替。\n",
    "\n",
    "|序号|不浮出水面是否可以生存|是否有脚蹼|属于鱼类|\n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "|1|是|是|是|\n",
    "|2|是|是|是|\n",
    "|3|是|否|否|\n",
    "|4|否|是|否|\n",
    "|5|否|是|否|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
      "['no surfacing', 'flippers']\n"
     ]
    }
   ],
   "source": [
    "def create_data_set():\n",
    "    data_set = [\n",
    "        [1, 1, 'yes'],\n",
    "        [1, 1, 'yes'],\n",
    "        [1, 0, 'no'],\n",
    "        [0, 1, 'no'],\n",
    "        [0, 1, 'no']\n",
    "    ]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return data_set, labels\n",
    "data_set, data_labels = create_data_set()\n",
    "print(data_set)\n",
    "print(data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 计算给定数据集的信息熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "def calc_entropy(data_set):\n",
    "    num_data = len(data_set)\n",
    "    label_counts = {}\n",
    "    for data in data_set:\n",
    "        current_label = data[-1]\n",
    "        if current_label not in label_counts.keys():\n",
    "            label_counts[current_label] = 0\n",
    "        label_counts[current_label] += 1\n",
    "    entropy = 0.0\n",
    "    for key in label_counts:\n",
    "        prob = float(label_counts[key])/num_data\n",
    "        entropy -= prob * log(prob, 2)\n",
    "    return entropy\n",
    "entropy = calc_entropy(data_set)\n",
    "entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 创建划分数据集方法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_set： [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
      "re_data： [[1, 'yes'], [1, 'yes'], [0, 'no']]\n"
     ]
    }
   ],
   "source": [
    "def split_data_set(data_set, axis, value):\n",
    "    re_data_set = []\n",
    "    for data in data_set:\n",
    "        if data[axis] == value:\n",
    "            re_data = data[:axis]         # 将data列表中该特征之前的特征放到re_data列表中\n",
    "            re_data.extend(data[axis+1:]) # 将data列表中该特征之后的特征也放到re_data中，说白了就是剔除了特征值为value的特征\n",
    "            re_data_set.append(re_data)\n",
    "    return re_data_set\n",
    "# 测试\n",
    "print(\"data_set：\", data_set) # 再次打印上文的data_set\n",
    "re_data = split_data_set(data_set, 0, 1)\n",
    "print(\"re_data：\", re_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上述结果可以看出，我们在data_set数据集中将每个样本里符合第1个（即索引为0的）特征的值为1的样本提取出来了。\n",
    "\n",
    "##### 创建选择最优特征方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_best_feature(data_set):\n",
    "    num_feature = len(data_set[0]) - 1  # 这里减一是因为每个样本中最后一个值是标签，而不是特征值\n",
    "    num_data = len(data_set)\n",
    "    data_set_entropy = calc_entropy(data_set)\n",
    "    gain = 0.0\n",
    "    best_feature = -1\n",
    "    for i in range(num_feature):  \n",
    "        feature_list = [example[i] for example in data_set]\n",
    "        unique_values = set(feature_list)\n",
    "        new_entropy = 0.0\n",
    "        for value in unique_values:\n",
    "            re_data_set = split_data_set(data_set, i, value)\n",
    "            prob = len(re_data_set)/float(num_data)\n",
    "            new_entropy += prob * calc_entropy(re_data_set)\n",
    "        new_gain = data_set_entropy - new_entropy\n",
    "        if new_gain > gain:\n",
    "            gain = new_gain\n",
    "            best_feature = i\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "继续使用上文的data_set进行数据测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_feature = choose_best_feature(data_set)\n",
    "best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 递归创建决策树\n",
    "决策树递归结束的条件为下列两种情况：\n",
    "1. 遍历完所有划分数据集的特征\n",
    "2. 每个分支下的所有样本实例都具有相同的分类\n",
    "\n",
    "注：对于第一点，当遍历完所有特征后，如果发现子数据集中仍有多种标签分类，则采用少数服从多数的原则将该子集进行分类。下面的majority_class方法表达的就是这个意思。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "def majority_class(class_list):\n",
    "    class_count = {}\n",
    "    for cla in class_list:\n",
    "        if cla not in class_count.keys():\n",
    "            class_count[cla] = 0\n",
    "        class_count[cla] += 1\n",
    "    sorted_class_count = sorted(class_count.items(), key=operator.items(1), reverse=True)\n",
    "    return sorted_class_count[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解决完递归结束条件后，开始正式创建决策树："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tree(data_set, data_labels):\n",
    "    labels = data_labels[:] # 防止改变原data_labels列表\n",
    "    class_list = [example[-1] for example in data_set]\n",
    "    # 符合递归结束条件2\n",
    "    if class_list.count(class_list[0]) == len(class_list):\n",
    "        return class_list[0]\n",
    "    # 符合递归结束条件1\n",
    "    if len(data_set[0]) == 1:\n",
    "        return majority_class(class_list)\n",
    "    # 计算并获取最优特征 \n",
    "    best_feature = choose_best_feature(data_set)\n",
    "    best_feature_label = labels[best_feature]\n",
    "    decision_tree = {best_feature_label: {}}\n",
    "    del(labels[best_feature])\n",
    "    feature_values = [example[best_feature] for example in data_set]\n",
    "    unique_values = set(feature_values)\n",
    "    for value in unique_values:\n",
    "        sub_labels = labels[:]\n",
    "        decision_tree[best_feature_label][value] = create_tree(split_data_set(data_set, best_feature, value), sub_labels)\n",
    "    return decision_tree\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述代码首先创建class_list列表，其中包含了数据集的所有分类标签。通过对class_list列表的进行两步判断，看是否符合两个递归结束条件中的任意一个。接下来开始创建决策树，先获取最优特征，以及该特征的所有特征值，并将最优特征从特征标签中删除。根据特征值划分子集，对每个子集递归调用create_tree。为了在递归时不改变原data_labels，所以使用新变量labels代替原始列表，sub_labels的道理类似。\n",
    "\n",
    "##### 下面进行测试输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']],\n",
       " ['no surfacing', 'flippers'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试数据\n",
    "data_set, data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建决策树\n",
    "dt = create_tree(data_set,data_labels)\n",
    "dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 测试算法：使用决策树进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_label1： no\n",
      "class_label2： yes\n"
     ]
    }
   ],
   "source": [
    "def classify(tree, feature_labels, test_data):\n",
    "    first_str = list(tree.keys())[0]\n",
    "    second_dic = tree[first_str]\n",
    "    feat_index = feature_labels.index(first_str)\n",
    "    for key in second_dic.keys():\n",
    "        if test_data[feat_index] == key:\n",
    "            if type(second_dic[key]).__name__ == 'dict':\n",
    "                class_label = classify(second_dic[key], feature_labels, test_data)\n",
    "            else:\n",
    "                class_label = second_dic[key]\n",
    "    return class_label\n",
    "# 分类测试\n",
    "class_label1 = classify(dt, data_labels, [1, 0])\n",
    "class_label2 = classify(dt, data_labels, [1, 1])\n",
    "print(\"class_label1：\", class_label1)\n",
    "print(\"class_label2：\", class_label2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 用决策树预测隐形眼镜类型\n",
    "*这个例子是大部分人在学习决策树都会用到*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['young', 'myope', 'no', 'reduced', 'no lenses'],\n",
       " ['young', 'myope', 'no', 'normal', 'soft'],\n",
       " ['young', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       " ['young', 'myope', 'yes', 'normal', 'hard'],\n",
       " ['young', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       " ['young', 'hyper', 'no', 'normal', 'soft'],\n",
       " ['young', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       " ['young', 'hyper', 'yes', 'normal', 'hard'],\n",
       " ['pre', 'myope', 'no', 'reduced', 'no lenses'],\n",
       " ['pre', 'myope', 'no', 'normal', 'soft'],\n",
       " ['pre', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       " ['pre', 'myope', 'yes', 'normal', 'hard'],\n",
       " ['pre', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       " ['pre', 'hyper', 'no', 'normal', 'soft'],\n",
       " ['pre', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       " ['pre', 'hyper', 'yes', 'normal', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'no', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'no', 'normal', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'yes', 'normal', 'hard'],\n",
       " ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'hyper', 'no', 'normal', 'soft'],\n",
       " ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('lenses.txt', 'r') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    lenses = [line.split('\\t') for line in lines]\n",
    "lenses # 查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tearRate': {'normal': {'astigmatic': {'no': {'age': {'pre': 'soft',\n",
       "      'presbyopic': {'prescript': {'hyper': 'soft', 'myope': 'no lenses'}},\n",
       "      'young': 'soft'}},\n",
       "    'yes': {'prescript': {'hyper': {'age': {'pre': 'no lenses',\n",
       "        'presbyopic': 'no lenses',\n",
       "        'young': 'hard'}},\n",
       "      'myope': 'hard'}}}},\n",
       "  'reduced': 'no lenses'}}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenses_labels = ['age', 'prescript', 'astigmatic', 'tearRate'] \n",
    "lenses_tree = create_tree(lenses, lenses_labels)\n",
    "lenses_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 使用Matplotlib注解绘制树形图\n",
    "正如上面的结果所示，采用文本的当时输出一个决策树时我们很难分辨出该树的枝叶，所以接下来我们将采用注解的形式绘制出树形图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD6CAYAAACvZ4z8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIlJyLPREREqOhZ6ISMmx0BMRKbn/A0yTlg8W3f/UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x240103f5518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "decision_node = dict(boxstyle=\"sawtooth\", fc=\"0.8\")\n",
    "leaf_node = dict(boxstyle=\"round4\", fc=\"0.8\")\n",
    "arrow_args = dict(arrowstyle=\"<-\")\n",
    "\n",
    "def plot_node(node_txt, center_pt, parent_pt, node_type):\n",
    "    create_plot.axl.annotate(node_txt, xy=parent_pt, xycoords='axes fraction', xytext=center_pt, textcoords='axes fraction', \n",
    "                             va='center', ha='center', bbox=node_type, arrowprops=arrow_args)\n",
    "# 先来一个简单的画图测试\n",
    "def create_plot():\n",
    "    fig = plt.figure(1, facecolor='white')\n",
    "    fig.clf()\n",
    "    create_plot.axl = plt.subplot(111, frameon=False)\n",
    "    plot_node('决策节点', (0.5, 0.1), (0.1, 0.5), decision_node)\n",
    "    plot_node('叶子节点', (0.8, 0.1), (0.3, 0.8),leaf_node)\n",
    "    plt.show()\n",
    "create_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
